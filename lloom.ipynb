{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833f253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Step 1: Loading API Key...\n",
      "‚úÖ API Key loaded successfully\n",
      "\n",
      "üîç Step 2: Setting up model functions...\n",
      "‚úÖ Model functions ready\n",
      "\n",
      "üîç Step 3: Setting up call functions...\n",
      "‚úÖ Call functions ready\n",
      "\n",
      "üîç Step 4: Loading CSV file...\n",
      "‚úÖ Loaded 26 events\n",
      "\n",
      "üîç Step 5: Creating LLooM instance with Gemini models...\n",
      "   ‚öôÔ∏è  Setting up LLM...\n",
      "   ‚úÖ LLM setup complete\n",
      "   ‚öôÔ∏è  Setting up Embedding model...\n",
      "   ‚úÖ Embedding model setup complete\n",
      "   ‚öôÔ∏è  Setting up LLM...\n",
      "   ‚úÖ LLM setup complete\n",
      "   ‚öôÔ∏è  Setting up LLM...\n",
      "   ‚úÖ LLM setup complete\n",
      "No `id_col` provided. Created an ID column named 'id'.\n",
      "‚úÖ LLooM instance created successfully!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import text_lloom.workbench as wb\n",
    "from text_lloom.llm import Model, EmbedModel\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# --- Gemini API Key ---\n",
    "print(\"üîç Step 1: Loading API Key...\")\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"‚ùå Error: GOOGLE_API_KEY not found in .env\")\n",
    "    sys.exit(1)\n",
    "print(\"‚úÖ API Key loaded successfully\")\n",
    "\n",
    "# --- Model Setup ---\n",
    "\n",
    "print(\"\\nüîç Step 2: Setting up model functions...\")\n",
    "# SETUP functions\n",
    "def setup_llm_fn(api_key):\n",
    "    print(\"   ‚öôÔ∏è  Setting up LLM...\")\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    print(\"   ‚úÖ LLM setup complete\")\n",
    "    return client\n",
    "\n",
    "def setup_embed_fn(api_key):\n",
    "    print(\"   ‚öôÔ∏è  Setting up Embedding model...\")\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    print(\"   ‚úÖ Embedding model setup complete\")\n",
    "    return client\n",
    "\n",
    "print(\"‚úÖ Model functions ready\")\n",
    "\n",
    "# CALL functions\n",
    "print(\"\\nüîç Step 3: Setting up call functions...\")\n",
    "async def call_llm_fn(model, prompt):\n",
    "    if \"system_prompt\" not in model.args:\n",
    "        model.args[\"system_prompt\"] = \"You are a helpful assistant who helps with identifying patterns in text examples.\"\n",
    "    if \"temperature\" not in model.args:\n",
    "        model.args[\"temperature\"] = 0\n",
    "    \n",
    "    try:\n",
    "        # Check if json is requested in prompt to decide on response_mime_type\n",
    "        config = {\n",
    "            \"temperature\": model.args[\"temperature\"],\n",
    "            \"max_output_tokens\": 8192,\n",
    "        }\n",
    "        \n",
    "        # Only enforce JSON if it looks like the prompt expects it\n",
    "        if \"JSON\" in prompt or \"json\" in prompt:\n",
    "             config[\"response_mime_type\"] = \"application/json\"\n",
    "\n",
    "        res = model.client.models.generate_content(\n",
    "            model=model.name,\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        res_parsed = res.text if res and hasattr(res, 'text') else None\n",
    "        tokens = [0, 0]\n",
    "        return res_parsed, tokens\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå LLM Error: {str(e)}\")\n",
    "        return None, [0, 0]\n",
    "\n",
    "def call_embed_fn(model, text_arr):\n",
    "    print(f\"   üîó Embedding call initiated with {len(text_arr)} items...\")\n",
    "    \n",
    "    # Ensure text_arr is a list of strings\n",
    "    if isinstance(text_arr, str):\n",
    "        text_arr = [text_arr]\n",
    "    \n",
    "    # Filter out empty strings which cause API errors\n",
    "    valid_indices = [i for i, t in enumerate(text_arr) if t and isinstance(t, str) and t.strip()]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        print(\"   ‚ö†Ô∏è Warning: No valid text to embed.\")\n",
    "        return [[0.0] * 3072] * len(text_arr), [0, 0]  # CHANGED: 3072 dimensions\n",
    "    \n",
    "    filtered_text = [text_arr[i] for i in valid_indices]\n",
    "    embeddings_map = {} \n",
    "    \n",
    "    # Process in small batches\n",
    "    batch_size = 10\n",
    "    \n",
    "    for i in range(0, len(filtered_text), batch_size):\n",
    "        batch = filtered_text[i:i+batch_size]\n",
    "        start_idx = i\n",
    "        \n",
    "        max_retries = 3\n",
    "        batch_embeddings = []\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # CHANGED: Using gemini-embedding-001 (the working model)\n",
    "                res = model.client.models.embed_content(\n",
    "                    model=\"gemini-embedding-001\",\n",
    "                    contents=batch,\n",
    "                )\n",
    "                \n",
    "                # Extract embeddings - response has 'embeddings' attribute\n",
    "                if hasattr(res, 'embeddings') and res.embeddings:\n",
    "                    batch_embeddings = [e.values for e in res.embeddings]\n",
    "                \n",
    "                if batch_embeddings:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                sleep_time = 2 * (attempt + 1)\n",
    "                if \"429\" in str(e):\n",
    "                    print(f\"   ‚ö†Ô∏è Rate limited. Waiting {sleep_time}s...\")\n",
    "                elif \"500\" in str(e) or \"503\" in str(e):\n",
    "                    print(f\"   ‚ö†Ô∏è Server error. Waiting {sleep_time}s...\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Embedding Error: {str(e)}\")\n",
    "                    break\n",
    "                time.sleep(sleep_time)\n",
    "        \n",
    "        # Fill in embeddings for this batch\n",
    "        if batch_embeddings:\n",
    "             for j, emb in enumerate(batch_embeddings):\n",
    "                 if j < len(batch): \n",
    "                    original_idx = valid_indices[start_idx + j]\n",
    "                    embeddings_map[original_idx] = emb\n",
    "        else:\n",
    "            print(f\"   ‚ùå Batch failed (size {len(batch)}). API returned no embeddings.\")\n",
    "            raise RuntimeError(f\"Embedding failed for batch starting at {start_idx}\")\n",
    "\n",
    "    # reconstruct full list in original order\n",
    "    result_embeddings = []\n",
    "    for i in range(len(text_arr)):\n",
    "        if i in embeddings_map:\n",
    "            result_embeddings.append(embeddings_map[i])\n",
    "        else:\n",
    "            result_embeddings.append([0.0] * 3072)  # CHANGED: 3072 dimensions\n",
    "\n",
    "    tokens = [0, 0]\n",
    "    print(f\"   ‚úÖ Embedding complete. {len(result_embeddings)} vectors.\")\n",
    "    return result_embeddings, tokens\n",
    "\n",
    "print(\"‚úÖ Call functions ready\")\n",
    "\n",
    "# --- LLooM Instance ---\n",
    "\n",
    "print(\"\\nüîç Step 4: Loading CSV file...\")\n",
    "df = pd.read_csv(\"events.csv\")\n",
    "print(f\"‚úÖ Loaded {len(df)} events\")\n",
    "\n",
    "# Ensure we have enough data (duplicate if too small for testing UMAP)\n",
    "if len(df) < 15:\n",
    "    print(\"‚ö†Ô∏è Warning: Dataset is very small. Duplicating data for UMAP stability...\")\n",
    "    multiplier = (20 // len(df)) + 1\n",
    "    df = pd.concat([df] * multiplier, ignore_index=True)\n",
    "    print(f\"   New shape: {df.shape}\")\n",
    "\n",
    "print(\"\\nüîç Step 5: Creating LLooM instance with Gemini models...\")\n",
    "# Create the LLooM instance with custom Gemini models\n",
    "l = wb.lloom(\n",
    "    df=df,\n",
    "    text_col=\"event\",\n",
    "    \n",
    "    # Custom Gemini models\n",
    "    distill_model=Model(\n",
    "        setup_fn=setup_llm_fn,\n",
    "        fn=call_llm_fn,\n",
    "        name=\"gemini-2.5-flash\",\n",
    "        cost=[0.0005/1000, 0.0015/1000], \n",
    "        rate_limit=(60, 60), \n",
    "        context_window=32000, \n",
    "        api_key=api_key\n",
    "    ),\n",
    "    cluster_model=EmbedModel(\n",
    "        setup_fn=setup_embed_fn,\n",
    "        fn=call_embed_fn,\n",
    "        name=\"gemini-embedding-001\",  # CHANGED: from \"models/embedding-001\"\n",
    "        cost=(0.00001/1000), \n",
    "        batch_size=10, \n",
    "        api_key=api_key\n",
    "    ),\n",
    "    synth_model=Model(\n",
    "        setup_fn=setup_llm_fn,\n",
    "        fn=call_llm_fn,\n",
    "        name=\"gemini-2.5-flash\", \n",
    "        cost=[0.01/1000, 0.03/1000], \n",
    "        rate_limit=(60,60), \n",
    "        context_window=32000, \n",
    "        api_key=api_key\n",
    "    ),\n",
    "    score_model=Model(\n",
    "        setup_fn=setup_llm_fn,\n",
    "        fn=call_llm_fn,\n",
    "        name=\"gemini-2.5-flash\", \n",
    "        cost=[0.0005/1000, 0.0015/1000], \n",
    "        rate_limit=(60,60),\n",
    "        context_window=32000,\n",
    "        api_key=api_key\n",
    "        ),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLooM instance created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d501ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Running LLooM Auto Generation\n",
      "============================================================\n",
      "\n",
      "üìä Generating features with auto parameters...\n",
      "   (This may take several minutes...)\n",
      "\n",
      "Cost estimates not available for distill model `gemini-2.5-flash`\n",
      "Cost estimates not available for cluster model `gemini-embedding-001`\n",
      "Cost estimates not available for synth model `gemini-2.5-flash`\n",
      "\n",
      "\n",
      "\u001b[48;5;117mDistill-filter\u001b[0m\n",
      "‚úÖ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mDistill-summarize\u001b[0m\n",
      "‚úÖ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mCluster\u001b[0m\n",
      "‚†ã Loading   üîó Embedding call initiated with 10 items...\n",
      "‚†ß Loading    ‚úÖ Embedding complete. 10 vectors.\n",
      "   üîó Embedding call initiated with 10 items...\n",
      "‚†¥ Loading    ‚úÖ Embedding complete. 10 vectors.\n",
      "   üîó Embedding call initiated with 10 items...\n",
      "‚†ã Loading    ‚úÖ Embedding complete. 10 vectors.\n",
      "   üîó Embedding call initiated with 10 items...\n",
      "‚†º Loading    ‚úÖ Embedding complete. 10 vectors.\n",
      "   üîó Embedding call initiated with 10 items...\n",
      "‚†π Loading    ‚úÖ Embedding complete. 10 vectors.\n",
      "   üîó Embedding call initiated with 2 items...\n",
      "‚†ß Loading    ‚úÖ Embedding complete. 2 vectors.\n",
      "‚úÖ Done    \n",
      "\n",
      "\n",
      "\u001b[48;5;117mSynthesize\u001b[0m\n",
      "‚úÖ Done    \n",
      "‚úÖ Done with concept generation!\n",
      "\n",
      "\n",
      "\u001b[1mActive concepts\u001b[0m (n=5):\n",
      "- \u001b[1mMisconduct Allegations\u001b[0m: Does the text describe accusations, inappropriate behavior, harassment, or formal findings of misconduct against Lawrence Krauss?\n",
      "- \u001b[1mCareer Transition\u001b[0m: Does the text describe a change in Lawrence Krauss's employment or academic affiliation, such as leaving a university?\n",
      "- \u001b[1mAvailability & Travel\u001b[0m: Does the text describe someone's availability, travel plans, or scheduling details for meetings or events?\n",
      "- \u001b[1mMisconduct Allegations\u001b[0m: Does the text refer to allegations, complaints, or investigations related to sexual harassment or misconduct?\n",
      "- \u001b[1mConsensual Interactions\u001b[0m: Does the text describe consensual personal interactions, relationships, or mutual decisions regarding intimate encounters?\n",
      "Cost estimates not available for score model `gemini-2.5-flash`\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]ERROR json_load on: {\n",
      "    \"pattern_results\": [\n",
      "        {\n",
      "            \"example_id\": \"2\",\n",
      "            \"rationale\": \"The email's subject line and content summary explicitly mention an inquiry regarding \\\\\"allegations of sexual harassment.\\\\\"\",\n",
      "            \"answer\": \"A\",\n",
      "            \"quote\": \"Subject: Re: URGENT: BuzzFeed News inquiry re allegations of sexual harassment\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [08:55<00:00, 107.08s/it]\n",
      "‚úÖ Done with concept scoring!\n",
      "\n",
      "‚úÖ Generation and scoring complete!\n",
      "   Score DataFrame shape: (130, 9)\n",
      "\n",
      "üìã Score Results Preview:\n",
      "  doc_id                                               text  \\\n",
      "0      0  Type: digital_communication\\nParties: jeffrey ...   \n",
      "1      1  Parties: J, Karp, Brad S\\nThe text states: 'Fr...   \n",
      "2      2  'From: Lawrence Krauss\\nTo: Lawrence Krauss\\nS...   \n",
      "3      3  'just got out of a meeting'\\n'On Dec 11, 2017,...   \n",
      "4      4  I am now leaving for a 2 hour \\ndrive to a boo...   \n",
      "5      5  Parties: Peter Aldhous, Lawrence Krauss\\nrefer...   \n",
      "6      6  Why do you think that multiple women, over mor...   \n",
      "7      7  On 12/11/17 9:18 AM, Lawrence Krauss wrote: \\n...   \n",
      "8      8  'I am currently on a plane until noon pacific ...   \n",
      "9      9  I'm a reporter for BuzzFeed News who has been ...   \n",
      "\n",
      "                             concept_id            concept_name  \\\n",
      "0  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "1  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "2  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "3  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "4  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "5  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "6  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "7  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "8  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "9  e13b9349-f863-4f55-ab09-b26b38c286de  Misconduct Allegations   \n",
      "\n",
      "                                      concept_prompt  score  \\\n",
      "0  Does the text describe accusations, inappropri...    0.0   \n",
      "1  Does the text describe accusations, inappropri...    0.0   \n",
      "2  Does the text describe accusations, inappropri...    1.0   \n",
      "3  Does the text describe accusations, inappropri...    0.0   \n",
      "4  Does the text describe accusations, inappropri...    0.0   \n",
      "5  Does the text describe accusations, inappropri...    0.0   \n",
      "6  Does the text describe accusations, inappropri...    1.0   \n",
      "7  Does the text describe accusations, inappropri...    0.0   \n",
      "8  Does the text describe accusations, inappropri...    0.0   \n",
      "9  Does the text describe accusations, inappropri...    0.5   \n",
      "\n",
      "                                           rationale  \\\n",
      "0  The text is a brief email between \"jeffrey E.\"...   \n",
      "1  The provided text discusses a tax investigatio...   \n",
      "2  The text explicitly mentions a \"BuzzFeed News ...   \n",
      "3  The text only describes Lawrence Krauss statin...   \n",
      "4  The text describes a person leaving for a book...   \n",
      "5  The text describes a consensual encounter wher...   \n",
      "6  The text explicitly states that multiple women...   \n",
      "7  The provided text is an email from Lawrence Kr...   \n",
      "8  The provided text describes Lawrence Krauss's ...   \n",
      "9  The text explicitly mentions \"sexual misconduc...   \n",
      "\n",
      "                                           highlight  concept_seed  \n",
      "0                                   getting hotter '           NaN  \n",
      "1  Shares a link to a MarketWatch article about a...           NaN  \n",
      "2  Subject: Re: URGENT: BuzzFeed News inquiry re ...           NaN  \n",
      "3  Lawrence Krauss states he 'just got out of a m...           NaN  \n",
      "4  I am now leaving for a 2 hour \\ndrive to a boo...           NaN  \n",
      "5  refers to a consensual encounter in my hotel r...           NaN  \n",
      "6  Why do you think that multiple women, over mor...           NaN  \n",
      "7  I am currently on a plane until noon pacific time           NaN  \n",
      "8  Lawrence Krauss states he is 'heading to a mee...           NaN  \n",
      "9  I'm a reporter for BuzzFeed News who has been ...           NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Running LLooM Auto Generation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä Generating features with auto parameters...\")\n",
    "print(\"   (This may take several minutes...)\\n\")\n",
    "\n",
    "# Run gen_auto without interactive prompt by using debug=False\n",
    "score_df = await l.gen_auto(\n",
    "    max_concepts=5,\n",
    "    debug=False  # Skip interactive prompt\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Generation and scoring complete!\")\n",
    "print(f\"   Score DataFrame shape: {score_df.shape if score_df is not None else 'None'}\")\n",
    "\n",
    "# Display results\n",
    "if score_df is not None:\n",
    "    print(\"\\nüìã Score Results Preview:\")\n",
    "    print(score_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0ee11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54e98e614894e28aed0bccf765181c4",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<text_lloom.__init__.ConceptSelectWidget object at 0x13e47c1d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc906660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0d285754cb43268c0bf3a4e07aab08",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<text_lloom.__init__.MatrixWidget object at 0x110ca8990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b579b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mActive concepts\u001b[0m (n=14):\n",
      "- \u001b[1mHarassment Allegation Inquiry\u001b[0m: Does the text describe an inquiry, allegation, or specific comment related to harassment, discrimination, or bias?\n",
      "- \u001b[1mDinner Invitation Event\u001b[0m: Does the text mention an invitation, specifically for dinner, or a dinner event occurring at a specific time or place?\n",
      "- \u001b[1mUniversity Job Change\u001b[0m: Does the text describe someone joining a new university position or leaving one institution for another?\n",
      "- \u001b[1mMisconduct Allegations\u001b[0m: Does the text describe accusations, inappropriate behavior, harassment, or formal findings of misconduct against Lawrence Krauss?\n",
      "- \u001b[1mPublic Engagements\u001b[0m: Does the text describe Lawrence Krauss participating in public events, conventions, social gatherings, or professional meetings?\n",
      "- \u001b[1mInternal Communications\u001b[0m: Does the text describe Lawrence Krauss's internal emails, administrative meetings, or formal communications within an organization?\n",
      "- \u001b[1mEpstein Controversy\u001b[0m: Does the text mention Lawrence Krauss's involvement with or comments regarding Jeffrey Epstein?\n",
      "- \u001b[1mCareer Transition\u001b[0m: Does the text describe a change in Lawrence Krauss's employment or academic affiliation, such as leaving a university?\n",
      "- \u001b[1mAvailability & Travel\u001b[0m: Does the text describe someone's availability, travel plans, or scheduling details for meetings or events?\n",
      "- \u001b[1mMisconduct Allegations\u001b[0m: Does the text refer to allegations, complaints, or investigations related to sexual harassment or misconduct?\n",
      "- \u001b[1mConsensual Interactions\u001b[0m: Does the text describe consensual personal interactions, relationships, or mutual decisions regarding intimate encounters?\n",
      "- \u001b[1mInformation Sharing\u001b[0m: Does the text involve sharing general news, articles, or non-personal updates and messages?\n",
      "- \u001b[1mSpecific Event Dates\u001b[0m: Does the text mention a specific event, meeting, or incident along with a precise date or time?\n",
      "- \u001b[1mCareer Transition\u001b[0m: Does the text announce a significant personal or professional transition, such as a job change or relocation?\n"
     ]
    }
   ],
   "source": [
    "l.show_selected()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
